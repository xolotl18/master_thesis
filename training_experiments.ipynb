{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q0h5Lhdc8pCj"
   },
   "source": [
    "# Semantic Segmentation with FastSCNN - changing network structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3B_C0udn81Wl"
   },
   "source": [
    "The purpose of this model is to train the network on the train dataset and then export the model in onnx format and also save the state_dict of the pytorch model for later inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Do not run this cell outside of Google Colaboratory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MsUVejuD8NE4",
    "outputId": "259b9f11-9def-482c-aaff-65b76d14c9ff"
   },
   "outputs": [],
   "source": [
    "!pip3 install -q -U albumentations\n",
    "!echo \"$(pip freeze | grep albumentations) is successfully installed\"\n",
    "!pip uninstall opencv-python-headless==4.5.5.62\n",
    "!pip install opencv-python-headless==4.5.2.52\n",
    "!pip install torchmetrics\n",
    "!pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 torchaudio==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "!git clone https://github.com/xolotl18/Master_Thesis\n",
    "!pip install onnx\n",
    "!pip install onnxruntime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ToEHpxrS9YrK"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "DNzYJzDG8oTS"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "import albumentations as A\n",
    "import albumentations.augmentations.functional as F\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchmetrics import JaccardIndex\n",
    "from statistics import mean\n",
    "import torchvision.transforms as T\n",
    "import torch.onnx\n",
    "import onnx\n",
    "import onnxruntime\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "from utils.lr_scheduler import PolynomialLRDecay\n",
    "from models.fast_scnn import FastSCNN\n",
    "from models.small_scnn import SmallSCNN\n",
    "from models.super_small_scnn import SuperSmallSCNN\n",
    "\n",
    "from models.experiments.fast_scnn_mod import FastSCNN as fastscnn_mod\n",
    "\n",
    "from models.bisenetv2 import BiSeNetV2\n",
    "from utils.dataset import PackagesDataset, PackagesInferenceDataset\n",
    "from utils.evaluation import Evaluate\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ly8xqG0BpMa"
   },
   "source": [
    "## Load image and label files into Dataset objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o8zTRzUcB26B"
   },
   "source": [
    "The dataset has already been divided into train, validation and test folders in the notebook **Desktop/Master_Thesis/preparation/dataset_traintest_split.ipynb**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ht_TfMCX_YPU",
    "outputId": "90574f95-389a-4d0e-b9bb-087f6ee935ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the train set is : 300\n",
      "\n",
      "The size of the validation set is : 40\n",
      "\n",
      "The size of the test set is : 60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "c_dir = os.getcwd()\n",
    "dataset_directory = os.path.join(c_dir, \"full_dataset\")\n",
    "\n",
    "train_images_directory = os.path.join(dataset_directory, \"train/images\")\n",
    "train_masks_directory = os.path.join(dataset_directory, \"train/labels\")\n",
    "val_images_directory = os.path.join(dataset_directory, \"val/images\")\n",
    "val_masks_directory = os.path.join(dataset_directory, \"val/labels\")\n",
    "test_images_directory = os.path.join(dataset_directory, \"test/images\")\n",
    "test_masks_directory = os.path.join(dataset_directory, \"test/labels\")\n",
    "\n",
    "#make sure that image_filenames only contains png files\n",
    "train_images_filenames = []\n",
    "train_images_filenames = [ item for item in os.listdir(train_images_directory) if item.endswith(\".png\") ]\n",
    "val_images_filenames = []\n",
    "val_images_filenames = [ item for item in os.listdir(val_images_directory) if item.endswith(\".png\") ]\n",
    "test_images_filenames = []\n",
    "test_images_filenames = [ item for item in os.listdir(test_images_directory) if item.endswith(\".png\") ]\n",
    "\n",
    "for names_list, split in zip((train_images_filenames, val_images_filenames, test_images_filenames), ('train', 'validation', 'test')):\n",
    "  print(f\"The size of the {split} set is : {len(names_list)}\")\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HmSe1l8wDIgh"
   },
   "source": [
    "Select the transformations and create the Dataset objects. \n",
    "\n",
    "The test dataset is different from train and validation because it does not crop the image but applies a resize that will be reversed after the inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "u0mkcqVHA197"
   },
   "outputs": [],
   "source": [
    "train_transform = A.Compose(\n",
    "    [\n",
    "        A.PadIfNeeded(min_height=512, min_width=512),\n",
    "        A.RandomCrop(512, 512),\n",
    "        A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5),\n",
    "        A.RGBShift(r_shift_limit=15, g_shift_limit=15, b_shift_limit=15, p=0.3),\n",
    "        A.RandomBrightnessContrast(p=0.3),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "val_transform = A.Compose(\n",
    "    [\n",
    "        A.PadIfNeeded(min_height=512, min_width=512),\n",
    "        A.CenterCrop(512, 512),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "test_transform = A.Compose(\n",
    "    [\n",
    "        A.Resize(512, 512),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_dataset = PackagesDataset(train_images_filenames, train_images_directory, train_masks_directory, transform=train_transform,)\n",
    "val_dataset = PackagesDataset(val_images_filenames, val_images_directory, val_masks_directory, transform=val_transform,)\n",
    "test_dataset = PackagesInferenceDataset(test_images_filenames, test_images_directory, test_masks_directory, transform=test_transform,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5NMVGrX6FKCi",
    "tags": []
   },
   "source": [
    "## Training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "DeDfSTgaFytR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The device is : cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "  device = \"cuda\"\n",
    "else:\n",
    "  device = \"cpu\"\n",
    "\n",
    "params = {\n",
    "    \"device\" : device,\n",
    "    \"lr\" : 0.01,\n",
    "    \"batch_size\" : 8,\n",
    "    \"num_workers\" : 4,\n",
    "    \"epochs\" : 400,\n",
    "}\n",
    "print(f\"The device is : {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "GeVIeZ9GDdu9"
   },
   "outputs": [],
   "source": [
    "#these functions are modified to show less information \n",
    "#the output of 400 epochs of training takes up too much space\n",
    "def train(train_loader, model, criterion, optimizer, scheduler, epoch, params):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 1):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        images, targets = data\n",
    "        images = images.to(params[\"device\"], non_blocking=True)\n",
    "        targets = targets.to(params[\"device\"], non_blocking=True)\n",
    "\n",
    "        outputs = model(images)\n",
    "        targets = torch.unsqueeze(targets, 1)\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step(epoch)\n",
    "        running_loss += loss.item()*images.size(0)\n",
    "\n",
    "def validate(val_loader, model, criterion, epoch, params):\n",
    "    model.eval()\n",
    "    running_loss=0.0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(val_loader, start=1):\n",
    "                images, targets = data\n",
    "                images = images.to(params[\"device\"], non_blocking=True)\n",
    "                targets = targets.to(params[\"device\"], non_blocking=True)\n",
    "                output = model(images).squeeze(1)\n",
    "                loss = criterion(output, targets)\n",
    "                running_loss += loss.item()*images.size(0)\n",
    "    return running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, params, test_dataset):\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, batch_size=params[\"batch_size\"], shuffle=False, num_workers=params[\"num_workers\"], pin_memory=True,\n",
    "    )\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for images, masks, (original_heights, original_widths) in test_loader:\n",
    "            images = images.to(params[\"device\"], non_blocking=True)\n",
    "            output = model(images)\n",
    "            probabilities = torch.sigmoid(output.squeeze(1))\n",
    "            predicted_masks = (probabilities >= 0.5).float() * 1\n",
    "            predicted_masks = predicted_masks.cpu().numpy()\n",
    "            for predicted_mask, gt, original_height, original_width in zip(\n",
    "                predicted_masks, masks.numpy(), original_heights.numpy(), original_widths.numpy()\n",
    "            ):\n",
    "                predictions.append((predicted_mask, gt, original_height, original_width))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_initializer_from_input(model_path):\n",
    "\n",
    "    onnxmodel = onnx.load(model_path+\".onnx\")\n",
    "    if onnxmodel.ir_version < 4:\n",
    "        print(\"Model with ir_version below 4 requires to include initilizer in graph input\")\n",
    "        return\n",
    "\n",
    "    inputs = onnxmodel.graph.input\n",
    "    name_to_input = {}\n",
    "    for input in inputs:\n",
    "        name_to_input[input.name] = input\n",
    "\n",
    "    for initializer in onnxmodel.graph.initializer:\n",
    "        if initializer.name in name_to_input:\n",
    "            inputs.remove(name_to_input[initializer.name])\n",
    "    out_path = model_path+\"_noinit.onnx\"\n",
    "    onnx.save(onnxmodel, out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will define a sequence of hyperparameters that will define the structure of the network. By iterating over these combinations of hyperparameters we will train different models one after the other and save the torch state_dict and the onnx model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the list of parameters contains tuples corresponding to a t r pp\n",
    "#these parameters make up the first 2 stages of simplification\n",
    "#after the models are trained and evaluated, a combination of the results from\n",
    "#these 2 stages will make up the third stage of simplification\n",
    "parameters1_2 = [\n",
    "    (1.0, 6, 3, True),    #baseline\n",
    "    (0.75, 6, 3, True),\n",
    "    (0.5, 6, 3, True),\n",
    "    (0.25, 6, 3, True),\n",
    "    (0.125, 6, 3, True),\n",
    "    (0.5, 4, 3, True),\n",
    "    (0.25, 4, 3, True),\n",
    "    (0.125, 4, 3, True),\n",
    "    (0.25, 2, 3, True),\n",
    "    (0.125, 2, 3, True),\n",
    "    (1.0, 6, 3, False),\n",
    "    (1.0, 6, 2, True),\n",
    "    (1.0, 6, 1, True),\n",
    "    (1.0, 6, 1, False),   \n",
    "]\n",
    "\n",
    "parameters3 = [\n",
    "    (0.25, 6, 2, False),\n",
    "    (0.25, 6, 1, False),\n",
    "    (0.25, 4, 2, False),\n",
    "    (0.25, 4, 1, False),\n",
    "    (0.25, 2, 2, False),\n",
    "    (0.25, 2, 1, False),\n",
    "    (0.125, 6, 2, False),\n",
    "    (0.125, 6, 1, False),\n",
    "    (0.125, 4, 2, False),\n",
    "    (0.125, 4, 1, False),\n",
    "    (0.125, 2, 2, False),\n",
    "    (0.125, 2, 1, False),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=params[\"batch_size\"],\n",
    "    shuffle=True,\n",
    "    num_workers=params[\"num_workers\"],\n",
    "    pin_memory=False,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=params[\"batch_size\"],\n",
    "    shuffle=True,\n",
    "    num_workers=params[\"num_workers\"],\n",
    "    pin_memory=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has been initialized with parameters:\n",
      "\t Width multiplier a =  0.25\n",
      "\t Bottleneck expansion rate t =  6\n",
      "\t Bottleneck block repetition r =  2\n",
      "\t Presence of Pyramid Pooling module pp =  False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec237a3c34ec40fab835873003c2f8ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Intersection over Union score is : 0.9735\n",
      "The Dice Coefficient is : 0.9866\n",
      "\n",
      "Torch state_dict saved\n",
      "Onnx model saved\n",
      "\n",
      "The model has been initialized with parameters:\n",
      "\t Width multiplier a =  0.25\n",
      "\t Bottleneck expansion rate t =  6\n",
      "\t Bottleneck block repetition r =  1\n",
      "\t Presence of Pyramid Pooling module pp =  False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bed1685140684ea3a703f788f89c2cc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Intersection over Union score is : 0.9745\n",
      "The Dice Coefficient is : 0.9871\n",
      "\n",
      "Torch state_dict saved\n",
      "Onnx model saved\n",
      "\n",
      "The model has been initialized with parameters:\n",
      "\t Width multiplier a =  0.25\n",
      "\t Bottleneck expansion rate t =  4\n",
      "\t Bottleneck block repetition r =  2\n",
      "\t Presence of Pyramid Pooling module pp =  False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db0dd495873348f8b42ef116f3034a76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Intersection over Union score is : 0.9705\n",
      "The Dice Coefficient is : 0.9850\n",
      "\n",
      "Torch state_dict saved\n",
      "Onnx model saved\n",
      "\n",
      "The model has been initialized with parameters:\n",
      "\t Width multiplier a =  0.25\n",
      "\t Bottleneck expansion rate t =  4\n",
      "\t Bottleneck block repetition r =  1\n",
      "\t Presence of Pyramid Pooling module pp =  False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93f3d9b7f8874e27b8e2622ab866f2d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Intersection over Union score is : 0.9735\n",
      "The Dice Coefficient is : 0.9866\n",
      "\n",
      "Torch state_dict saved\n",
      "Onnx model saved\n",
      "\n",
      "The model has been initialized with parameters:\n",
      "\t Width multiplier a =  0.25\n",
      "\t Bottleneck expansion rate t =  2\n",
      "\t Bottleneck block repetition r =  2\n",
      "\t Presence of Pyramid Pooling module pp =  False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9f028ab13b84a76ba0353e9c8df8cb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Intersection over Union score is : 0.9723\n",
      "The Dice Coefficient is : 0.9859\n",
      "\n",
      "Torch state_dict saved\n",
      "Onnx model saved\n",
      "\n",
      "The model has been initialized with parameters:\n",
      "\t Width multiplier a =  0.25\n",
      "\t Bottleneck expansion rate t =  2\n",
      "\t Bottleneck block repetition r =  1\n",
      "\t Presence of Pyramid Pooling module pp =  False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c19420cc9ed242599fa87d1d39e6a42d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Intersection over Union score is : 0.9694\n",
      "The Dice Coefficient is : 0.9844\n",
      "\n",
      "Torch state_dict saved\n",
      "Onnx model saved\n",
      "\n",
      "The model has been initialized with parameters:\n",
      "\t Width multiplier a =  0.125\n",
      "\t Bottleneck expansion rate t =  6\n",
      "\t Bottleneck block repetition r =  2\n",
      "\t Presence of Pyramid Pooling module pp =  False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d01d4d9cab1a469d8a57e816c6133512",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Intersection over Union score is : 0.9737\n",
      "The Dice Coefficient is : 0.9867\n",
      "\n",
      "Torch state_dict saved\n",
      "Onnx model saved\n",
      "\n",
      "The model has been initialized with parameters:\n",
      "\t Width multiplier a =  0.125\n",
      "\t Bottleneck expansion rate t =  6\n",
      "\t Bottleneck block repetition r =  1\n",
      "\t Presence of Pyramid Pooling module pp =  False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "908a9f011a9a41d5af6cdc9c7a7ffefd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Intersection over Union score is : 0.9694\n",
      "The Dice Coefficient is : 0.9844\n",
      "\n",
      "Torch state_dict saved\n",
      "Onnx model saved\n",
      "\n",
      "The model has been initialized with parameters:\n",
      "\t Width multiplier a =  0.125\n",
      "\t Bottleneck expansion rate t =  4\n",
      "\t Bottleneck block repetition r =  2\n",
      "\t Presence of Pyramid Pooling module pp =  False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92f8ba21f70a4be3b7c218bfda484444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Intersection over Union score is : 0.9704\n",
      "The Dice Coefficient is : 0.9850\n",
      "\n",
      "Torch state_dict saved\n",
      "Onnx model saved\n",
      "\n",
      "The model has been initialized with parameters:\n",
      "\t Width multiplier a =  0.125\n",
      "\t Bottleneck expansion rate t =  4\n",
      "\t Bottleneck block repetition r =  1\n",
      "\t Presence of Pyramid Pooling module pp =  False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7de9746d1296497da0160d930156bb97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Intersection over Union score is : 0.9613\n",
      "The Dice Coefficient is : 0.9802\n",
      "\n",
      "Torch state_dict saved\n",
      "Onnx model saved\n",
      "\n",
      "The model has been initialized with parameters:\n",
      "\t Width multiplier a =  0.125\n",
      "\t Bottleneck expansion rate t =  2\n",
      "\t Bottleneck block repetition r =  2\n",
      "\t Presence of Pyramid Pooling module pp =  False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc3d20b70d4c40fda02832f72d441a43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Intersection over Union score is : 0.9703\n",
      "The Dice Coefficient is : 0.9849\n",
      "\n",
      "Torch state_dict saved\n",
      "Onnx model saved\n",
      "\n",
      "The model has been initialized with parameters:\n",
      "\t Width multiplier a =  0.125\n",
      "\t Bottleneck expansion rate t =  2\n",
      "\t Bottleneck block repetition r =  1\n",
      "\t Presence of Pyramid Pooling module pp =  False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "067f0543eb1c4acf82948b2fbfc6e180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Intersection over Union score is : 0.9682\n",
      "The Dice Coefficient is : 0.9838\n",
      "\n",
      "Torch state_dict saved\n",
      "Onnx model saved\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for a, t, r, pp in parameters3:\n",
    "    model = fastscnn_mod(in_channels=3, num_classes=1, a=a, t=t, r=r, pp=pp).to(params[\"device\"])\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=params[\"lr\"])\n",
    "    scheduler = PolynomialLRDecay(optimizer, max_decay_steps=params[\"epochs\"], end_learning_rate=0.0001, power=0.9)\n",
    "\n",
    "    best_loss = sys.float_info.max\n",
    "    model_ckpt = copy.deepcopy(model.state_dict())\n",
    "    #train the current model\n",
    "    for epoch in tqdm(range(1, params[\"epochs\"]+1)):\n",
    "        train(train_loader, model, criterion, optimizer, scheduler, epoch, params)\n",
    "        epoch_loss = validate(val_loader, model, criterion, epoch, params)\n",
    "        #select the best model based on the loss on the validation set\n",
    "        if epoch_loss < best_loss:\n",
    "            best_loss = epoch_loss\n",
    "            model_ckpt = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "    model.load_state_dict(model_ckpt)\n",
    "    predictions = predict(model, params, test_dataset)\n",
    "    #display the intersecion over union and the dice score for the current model\n",
    "    evaluator = Evaluate(predictions)\n",
    "    iou, dice = evaluator.get_metrics().values()\n",
    "    print(f\"The Intersection over Union score is : {iou:.4f}\")\n",
    "    print(f\"The Dice Coefficient is : {dice:.4f}\")\n",
    "    print()\n",
    "    #select the name that the model will be saved with\n",
    "    model_name = \"fastscnn_a\"+str(a)+\"t\"+str(t)+\"r\"+str(r)+\"pp\"+str(int(pp))\n",
    "    model_path = os.path.join(c_dir, \"model_checkpoints/experiments\", model_name)\n",
    "    torch.save(model.state_dict(), model_path+\".pt\")\n",
    "    print(\"Torch state_dict saved\")\n",
    "    #put the model in inference mode\n",
    "    model.eval()\n",
    "    #generate dummy input for onnx export\n",
    "    x = torch.randn(1, 3, 512, 512, requires_grad=True).to(params[\"device\"])\n",
    "\n",
    "    # Export the model\n",
    "    torch.onnx.export(model,                     # model being run\n",
    "                      x,                         # model input (or a tuple for multiple inputs)\n",
    "                      model_path+\".onnx\",       # where to save the model (can be a file or file-like object)\n",
    "                      export_params=True,        # store the trained parameter weights inside the model file\n",
    "                      opset_version=11,          # the ONNX version to export the model to\n",
    "                      do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                      input_names = ['input'],   # the model's input names\n",
    "                      output_names = ['output'], # the model's output names\n",
    "                      operator_export_type=torch.onnx.OperatorExportTypes.ONNX,\n",
    "                      dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
    "                                    'output' : {0 : 'batch_size'}})\n",
    "    remove_initializer_from_input(model_path)\n",
    "    print(\"Onnx model saved\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOUbNM9vv8a2lLIS9oTCmUR",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
